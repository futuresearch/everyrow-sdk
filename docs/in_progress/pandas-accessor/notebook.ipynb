{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# everyrow Pandas Accessor\n",
    "\n",
    "This notebook demonstrates the `df.everyrow` pandas accessor - a fluent API for AI-powered DataFrame operations.\n",
    "\n",
    "Instead of:\n",
    "```python\n",
    "from everyrow.ops import screen\n",
    "result = await screen(task=\"...\", input=df)\n",
    "filtered_df = result.data\n",
    "```\n",
    "\n",
    "You can write:\n",
    "```python\n",
    "filtered_df = await df.everyrow.screen(\"...\")\n",
    "```\n",
    "\n",
    "Get an API key at [everyrow.io/api-key](https://everyrow.io/api-key) to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nfrom dotenv import load_dotenv\nfrom pydantic import BaseModel, Field\n\n# Importing from everyrow registers the df.everyrow accessor\nfrom everyrow import create_session\nfrom everyrow.task import EffortLevel\n\nload_dotenv()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Screen\n",
    "\n",
    "Filter rows using natural language criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.DataFrame([\n",
    "    {\"company\": \"Airtable\",  \"post\": \"Async-first team, 8+ yrs exp, $185-220K base\"},\n",
    "    {\"company\": \"Vercel\",    \"post\": \"Lead our NYC team. Competitive comp, DOE\"},\n",
    "    {\"company\": \"Notion\",    \"post\": \"In-office SF. Staff eng, $200K + equity\"},\n",
    "    {\"company\": \"Linear\",    \"post\": \"Bootcamp grads welcome! $85K, remote-friendly\"},\n",
    "    {\"company\": \"Descript\",  \"post\": \"Work from anywhere. Principal architect, $250K\"},\n",
    "    {\"company\": \"Retool\",    \"post\": \"Flexible location. Building infra. Comp TBD\"},\n",
    "])\n",
    "\n",
    "print(\"Input jobs:\")\n",
    "print(jobs.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic screen - returns DataFrame directly\n",
    "qualified_jobs = await jobs.everyrow.screen(\"\"\"\n",
    "    Qualifies if ALL THREE are met:\n",
    "    1. Remote-friendly (allows remote, hybrid, or distributed)\n",
    "    2. Senior-level (5+ yrs exp OR title includes Senior/Staff/Principal)\n",
    "    3. Salary disclosed (specific numbers like \"$150K\", not \"competitive\" or \"DOE\")\n",
    "\"\"\")\n",
    "\n",
    "print(\"Qualified jobs:\")\n",
    "print(qualified_jobs.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access metadata via last_result\n",
    "print(f\"Artifact ID: {jobs.everyrow.last_result.artifact_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. Rank\n",
    "\n",
    "Score and sort rows by qualitative factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = pd.DataFrame([\n",
    "    {\"name\": \"Alice\", \"background\": \"10 years ML at Google, PhD in NLP\"},\n",
    "    {\"name\": \"Bob\", \"background\": \"2 years as PM, MBA from Stanford\"},\n",
    "    {\"name\": \"Carol\", \"background\": \"5 years data science, built ML pipelines at Stripe\"},\n",
    "    {\"name\": \"Dave\", \"background\": \"Fresh bootcamp grad, passionate about AI\"},\n",
    "])\n",
    "\n",
    "print(\"Candidates:\")\n",
    "print(candidates.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank candidates by fit\n",
    "ranked = await candidates.everyrow.rank(\n",
    "    \"fit_score\",\n",
    "    task=\"Rank candidates by fit for a senior ML engineer role at a startup\",\n",
    "    field_type=\"float\",\n",
    "    ascending=False  # Best candidates first\n",
    ")\n",
    "\n",
    "print(\"Ranked candidates:\")\n",
    "print(ranked.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 3. Dedupe\n",
    "\n",
    "Remove duplicates when fuzzy matching isn't enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = pd.DataFrame([\n",
    "    {\"name\": \"Apple Inc.\", \"source\": \"SEC filings\"},\n",
    "    {\"name\": \"Apple\", \"source\": \"LinkedIn\"},\n",
    "    {\"name\": \"Google LLC\", \"source\": \"SEC filings\"},\n",
    "    {\"name\": \"Alphabet/Google\", \"source\": \"News article\"},\n",
    "    {\"name\": \"Meta Platforms\", \"source\": \"SEC filings\"},\n",
    "    {\"name\": \"Facebook (Meta)\", \"source\": \"Old database\"},\n",
    "])\n",
    "\n",
    "print(f\"Input companies ({len(companies)} rows):\")\n",
    "print(companies.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dedupe by company identity\n",
    "unique = await companies.everyrow.dedupe(\n",
    "    \"Same company, accounting for legal suffixes, parent/subsidiary, and rebranding\"\n",
    ")\n",
    "\n",
    "print(f\"Unique companies ({len(unique)} rows):\")\n",
    "print(unique.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 4. Merge\n",
    "\n",
    "Join tables when keys don't match exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsidiaries = pd.DataFrame([\n",
    "    {\"name\": \"YouTube\", \"product\": \"Video streaming\"},\n",
    "    {\"name\": \"Instagram\", \"product\": \"Photo sharing\"},\n",
    "    {\"name\": \"WhatsApp\", \"product\": \"Messaging\"},\n",
    "    {\"name\": \"GitHub\", \"product\": \"Code hosting\"},\n",
    "])\n",
    "\n",
    "parents = pd.DataFrame([\n",
    "    {\"company\": \"Alphabet Inc.\", \"market_cap_b\": 2000},\n",
    "    {\"company\": \"Meta Platforms\", \"market_cap_b\": 1200},\n",
    "    {\"company\": \"Microsoft Corp\", \"market_cap_b\": 3000},\n",
    "])\n",
    "\n",
    "print(\"Subsidiaries:\")\n",
    "print(subsidiaries.to_string())\n",
    "print(\"\\nParent companies:\")\n",
    "print(parents.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge subsidiaries to parents\n",
    "merged = await subsidiaries.everyrow.merge(\n",
    "    parents,\n",
    "    task=\"Match each subsidiary to its parent company\",\n",
    "    left_on=\"name\",\n",
    "    right_on=\"company\"\n",
    ")\n",
    "\n",
    "print(\"Merged data:\")\n",
    "print(merged.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access merge breakdown\n",
    "breakdown = subsidiaries.everyrow.last_result.breakdown\n",
    "print(f\"Exact matches: {len(breakdown.exact)}\")\n",
    "print(f\"Fuzzy matches: {len(breakdown.fuzzy)}\")\n",
    "print(f\"LLM matches: {len(breakdown.llm)}\")\n",
    "print(f\"Web-assisted matches: {len(breakdown.web)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 5. Agent Map\n",
    "\n",
    "Run AI research on every row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "startups = pd.DataFrame([\n",
    "    {\"company\": \"Stripe\"},\n",
    "    {\"company\": \"Databricks\"},\n",
    "    {\"company\": \"Figma\"},\n",
    "])\n",
    "\n",
    "print(\"Startups to research:\")\n",
    "print(startups.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define structured output\n",
    "class CompanyInfo(BaseModel):\n",
    "    founded_year: int = Field(description=\"Year the company was founded\")\n",
    "    hq_city: str = Field(description=\"Headquarters city\")\n",
    "    latest_valuation_b: float = Field(description=\"Latest valuation in billions USD\")\n",
    "\n",
    "# Research each company\n",
    "enriched = await startups.everyrow.agent_map(\n",
    "    \"Research this company's founding year, HQ location, and latest valuation\",\n",
    "    effort_level=EffortLevel.MEDIUM,\n",
    "    response_model=CompanyInfo\n",
    ")\n",
    "\n",
    "print(\"Enriched data:\")\n",
    "print(enriched.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 6. Single Agent\n",
    "\n",
    "Run AI analysis on the entire DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.DataFrame([\n",
    "    {\"month\": \"Jan\", \"revenue\": 100000, \"customers\": 50},\n",
    "    {\"month\": \"Feb\", \"revenue\": 120000, \"customers\": 55},\n",
    "    {\"month\": \"Mar\", \"revenue\": 95000, \"customers\": 48},\n",
    "    {\"month\": \"Apr\", \"revenue\": 140000, \"customers\": 62},\n",
    "    {\"month\": \"May\", \"revenue\": 160000, \"customers\": 70},\n",
    "])\n",
    "\n",
    "print(\"Sales data:\")\n",
    "print(sales.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the data\n",
    "analysis = await sales.everyrow.single_agent(\n",
    "    \"Analyze this sales data. Identify trends, anomalies, and provide recommendations.\"\n",
    ")\n",
    "\n",
    "print(\"Analysis:\")\n",
    "print(analysis.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 7. Chaining Operations\n",
    "\n",
    "Operations return DataFrames, so you can chain them naturally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Screen vendors, then rank the qualified ones\n",
    "vendors = pd.DataFrame([\n",
    "    {\"company\": \"Acme Corp\", \"category\": \"Cloud Infrastructure\"},\n",
    "    {\"company\": \"Beta Inc\", \"category\": \"Security\"},\n",
    "    {\"company\": \"Gamma Ltd\", \"category\": \"Cloud Infrastructure\"},\n",
    "    {\"company\": \"Delta Co\", \"category\": \"Analytics\"},\n",
    "])\n",
    "\n",
    "# Chain: screen then rank\n",
    "qualified = await vendors.everyrow.screen(\n",
    "    \"Filter to cloud infrastructure vendors only\"\n",
    ")\n",
    "\n",
    "ranked_qualified = await qualified.everyrow.rank(\n",
    "    \"reliability_score\",\n",
    "    task=\"Rank cloud infrastructure vendors by reliability and uptime reputation\",\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "print(\"Top qualified vendors:\")\n",
    "print(ranked_qualified.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 8. Using Sessions\n",
    "\n",
    "For multiple operations, use an explicit session to group them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from everyrow import create_session\n",
    "\n",
    "async with create_session(name=\"Vendor Analysis\") as session:\n",
    "    print(f\"Session URL: {session.get_url()}\")\n",
    "    \n",
    "    # All operations share the same session\n",
    "    screened = await vendors.everyrow.with_session(session).screen(\n",
    "        \"Filter to security vendors\"\n",
    "    )\n",
    "    \n",
    "    ranked = await screened.everyrow.with_session(session).rank(\n",
    "        \"trust_score\",\n",
    "        task=\"Rank by security certifications and compliance\",\n",
    "        ascending=False\n",
    "    )\n",
    "    \n",
    "    print(\"Top security vendors:\")\n",
    "    print(ranked.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}